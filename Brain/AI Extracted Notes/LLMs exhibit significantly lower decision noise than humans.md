## EXTRACTED INSIGHT

**Title**: [[LLMs exhibit significantly lower decision noise than humans]]
**Type**: Experience-Based Wisdom / Research Finding
**Source**: YourWay Substack - AI vs Humans: A Noise Audit in Decision-Making (Research with Prof. Virginia Cha, NUS)
**Uniqueness**: Eugene's original research comparing GPT-3.5, GPT-4, and 52 human EMBA participants on decision noise
**Extracted By**: AI (insight-extractor agent)
**Extraction Date**: 2025-10-26

---

**Core Insight** (in Eugene's voice):

"We see that both the GPT-3.5 and GPT-4 Large Language Models have lower noise compared to human decision makers in the EMBA program (4.1% and 5.5%, respectively, for LLMs versus 16.4% on average for humans)."

---

**Context & Reasoning**:

Eugene and Professor Virginia Cha conducted empirical research using:
- 20 business decision questions across 4 categories (Rating, Categorical, Estimation, Decision Thresholds)
- Fictitious company (TechSolutions Inc.) with enough detail for judgment
- 2000 LLM data points (GPT-3.5 and GPT-4 at different temperatures)
- 52 human EMBA participants as control

**Key Findings**:

**1. Noise Levels**:
- GPT-4: 4.1% average noise
- GPT-3.5: 5.5% average noise
- Humans: 16.4% average noise
- LLMs are **3-4x more consistent** than humans

**2. Temperature Effect**:
- Higher temperature increases LLM noise (as hypothesized)
- But even at high temperature, LLM noise remains lower than humans

**3. Architecture Improvements Don't Reduce Noise**:
- GPT-4 vs GPT-3.5 showed similar noise levels
- "The improvements in the architecture of GPT-4 over its predecessor didn't result in a significant reduction in noise"
- Surprising finding: better model ≠ more consistent

**4. Critical Caveat**:
"While LLMs have lower noise levels than human participants, this doesn't necessarily mean that they always make better or more accurate decisions. LLMs still rely on the information they have been trained on, which isn't always applicable to the specific context of a given problem."

**Implication**:
- **Low noise ≠ high accuracy**
- Consistency is necessary but not sufficient for good decisions
- LLMs are reliably consistent (low noise) but may be consistently wrong (if training data misleading)

---

**Context & Reasoning** (Ensemble vs Time Probability):

Eugene notes important methodological limitation:
"Direct comparison of LLM noise results to human noise is difficult because we're comparing ensemble probability (for humans) to time probability (for LLMs). This only gives a directional estimate."

More accurate comparison would require same person answering same question multiple times without memory.

---

**Potential Connections**:
- [[Noise is an undesirable variability of judgements]] - Core concept from Kahneman
- [[Consistency vs accuracy distinction]] - Low noise doesn't guarantee correctness
- [[LLM decision-making capabilities]] - Where AI excels vs humans
- [[Ensemble vs time probability]] - Different ways to measure variability
- [[Temperature parameter effects]] - How LLM settings affect consistency

**Keywords**: #research-finding #experience-based-wisdom #decision-noise #llm-vs-humans #consistency #ai-extracted
