# Confirmation bias shapes AI agent evaluation just like human relationships

**Source:** Eugene Kurogo LinkedIn - AI Agent Workflows
**Date Captured:** 2025-10-25
**Type:** Pattern Recognition / Personal Theory

## Insight

"When I work with more autonomous AI agents, I cannot get rid of the feeling of magic. Not as a sort of good characteristic of an agent that you know makes me feel like magic, but that not knowing exactly how intricate, complex, and interesting and useful prompts are on the other side. I am making my assumption on how good it is and my assumption stems from my confirmation bias and desire to either support or not support given agent. So it's like with people, I will not like how you know the answers to the questions and the magic that happens on the back-end. If I don't like an agent, that's another sort of characteristic of the kind of human relationships."

**Human-AI evaluation mirrors human-human relationships**: Confirmation bias shapes how we judge AI agent quality. Pre-existing disposition (support/oppose) filters interpretation of agent performance, just like personal relationships bias our judgment of people's actions.

## Context & Reasoning

Eugene identifies several layers of bias in AI evaluation:

**The "magic" problem**:
- Agents operate opaquely (can't see the internal prompts/reasoning)
- Humans project quality assumptions onto opaque systems
- These assumptions driven by confirmation bias

**The relationship parallel**:
- If you like an agent → interpret ambiguous results positively
- If you dislike an agent → interpret same results negatively
- Same dynamic as human relationships: "I will not like how you know the answers to the questions and the magic that happens on the back-end"

**Key insight**: "My assumption stems from my confirmation bias and desire to either support or not support given agent"

This creates a **subjective evaluation trap**:
1. Can't fully observe agent's reasoning (black box)
2. Must infer quality from outputs
3. Pre-existing bias filters interpretation
4. Creates self-reinforcing judgment loops

## Connection to Existing Knowledge

**Confirmation bias mechanics**:
- **[[Confirmation Bias]]** - Seeking/interpreting evidence that confirms existing beliefs
- **[[Confirmation bias reinforces Identity through confirming Beliefs]]** - Relationship with agent becomes part of identity
- **[[Identity is a set of beliefs about the world]]** - Belief about agent quality becomes part of self-concept

**Human relationship parallels**:
- **[[Social groups]]** - We form in-groups (trusted agents) and out-groups (distrusted agents)
- **[[Identity comes from social groups]]** - Relationships with AI agents may become social identity components
- **[[Us vs Them]]** - Can apply to AI agents as easily as humans

**Judgment and decision-making**:
- **[[Judgment is a measurement using a human mind]]** - AI quality assessment is non-verifiable judgment
- **[[Noise is undesirable variability of judgements]]** - Different users will judge same agent differently
- **[[Hindsight Bias]]** - Will reinterpret agent past performance based on current opinion

**Black box problem**:
- **[[Illusion of Understanding]]** - Think we understand agent quality without seeing internals
- **[[WYSIATI (What You See Is All There Is)]]** - Judge based only on visible outputs

## Uniqueness

**What makes this distinctive:**
- Explicitly recognizes confirmation bias in human-AI relationships (usually discussed for human-human only)
- Identifies "magic" (opacity) as the enabling condition for bias
- Draws direct parallel to human relationship dynamics
- Self-aware acknowledgment of own bias: "I cannot get rid of the feeling"

**Practical implication**:
- AI agent evaluation needs structured, bias-resistant protocols
- Can't trust intuitive judgments about agent quality
- Similar to blind testing in science

## Tags

#eugene-kurogo #linkedin #AI-agents #confirmation-bias #human-AI-relationships #evaluation #black-box #pattern-recognition #cognitive-bias #self-awareness
