# Agents lose big picture in long sessions like humans lose forest for trees

**Source:** Eugene Kurogo LinkedIn - AI Agent Workflows
**Date Captured:** 2025-10-25
**Type:** Pattern Recognition / Experience-Based Wisdom

## Insight

"Yeah, it's funny, but it looks like the longer agents work within one session, the more likely they are to lose the bigger picture. And it is kinda very similar with humans. The more you are in the daily minutia of things, the more you're losing the big picture. They end up being exactly the same."

AI agents exhibit the same cognitive degradation pattern as humans during extended focused work: **deep immersion in details causes loss of holistic understanding**. The longer an agent works on low-level tasks, the less it grasps the application holistically.

## Context & Reasoning

Eugene observes through direct experience:

"The longer I'm having them do stuff like writing similar pieces of code on the lower level of the application, the less I can count on them to understand application holistically. And of course I have to compensate for that based on providing higher level overview files and stuff like that."

**The degradation pattern**:
1. Agent starts with holistic context
2. Prolonged session on detailed/repetitive tasks
3. Context window fills with low-level minutiae
4. High-level architecture understanding degrades
5. Requires manual context refresh (overview files)

**Human parallel**:
- Developers lose architecture vision when deep in debugging
- "In the weeds" phenomenon
- Requires periodic zoom-out to regain perspective

## Connection to Existing Knowledge

**Cognitive architecture parallels**:
- **[[Attention and Focus]]** - Sustained narrow focus reduces peripheral awareness
- **[[Working Memory]]** - Limited capacity fills with recent details, displacing high-level structure
- **[[Context switching]]** - Requires deliberate shift to regain big picture

**Flow state connection**:
- **[[Flow consists of 4 stages - Struggle, Release, Flow, Recovery]]** - Recovery stage necessary to reset perspective
- Deep flow on details can create tunnel vision
- Need for periodic Release to regain overview

**Buddhism/Neuroscience**:
- **[[Here and Now]]** - Complete immersion in present task
- **[[Conceptualization]]** - Low-level work creates detailed conceptual frames that obscure meta-level understanding
- Default Mode Network deactivation during focus = loss of big-picture narrative thinking

## Uniqueness

**What makes this distinctive:**
- Identifies specific AI degradation pattern through direct observation
- Draws explicit human-AI cognitive parallel (not just metaphorical)
- Provides practical mitigation strategy (overview files for context refresh)
- Suggests AI and human cognition share fundamental architectural constraints

**Practical implication**:
- Long agent sessions require periodic high-level context injection
- Similar to code review practice: zoom out regularly
- Architecture documents become essential for agent performance, not just human onboarding

## Tags

#eugene-kurogo #linkedin #AI-agents #pattern-recognition #cognitive-degradation #context-management #human-AI-parallel #session-management #big-picture
