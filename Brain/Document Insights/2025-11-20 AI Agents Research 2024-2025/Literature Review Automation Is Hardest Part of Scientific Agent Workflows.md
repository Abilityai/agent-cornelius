# Literature Review Automation Is Hardest Part of Scientific Agent Workflows

**Source**: Agentic AI for Scientific Discovery Survey (arXiv 2503.08979v1)
**Authors**: Mourad Gridach, Jay Nanavati, et al. (IQVIA)
**Year**: 2025
**Document Type**: Research Survey
**Extracted By**: AI (document-insight-extractor agent)
**Extraction Date**: 2025-11-20
**Session**: 2025-11-20 AI Agents Research 2024-2025

---

## Core Insight

Autonomous AI agents demonstrate **high success rates** in data preparation, experimentation, and report writing for scientific research, but **performance drops significantly in literature review phase**. This represents the most significant obstacle in scientific agent workflows, revealing that contextual understanding and synthesis are harder than execution and documentation.

---

## Context & Evidence

**Agent Laboratory Framework** (Automated Research Lifecycle):
1. **Ideation**: Analyzing literature to identify knowledge gaps and propose novel hypotheses
2. **Experiment Design & Execution**: Planning and autonomously conducting experiments using robotic integration
3. **Data Analysis**: Processing datasets to extract meaningful patterns
4. **Paper Writing**: Synthesizing findings into publication-ready manuscripts

**Performance Breakdown**:
- **Data Preparation**: High success rate ✓
- **Experimentation**: High success rate ✓
- **Report Writing**: High success rate ✓
- **Literature Review**: **Significant performance drop** ✗

**Why Literature Review Is Harder**:
- Requires **contextual understanding** of field evolution
- Demands **synthesis** across disparate papers with conflicting findings
- Needs **critical evaluation** of methodology quality
- Involves **implicit knowledge** about what constitutes "important" work
- Requires understanding **research culture** and unstated assumptions

---

## Context & Evidence (Continued)

**Notable Scientific Agent Frameworks**:

**Chemistry**:
- **Coscientist**: GPT-4-powered agent with web search, code execution, robotic automation
- **ChemCrow**: GPT-4 + 18 domain-specific tools for synthesis and drug discovery
- **LLaMP**: Retrieval-augmented generation (RAG) for materials property prediction

**Biology**:
- **BIA (BioInformatics Agent)**: Single-cell RNA sequencing via chat
- **CellAgent**: Multi-agent system achieving **92% task completion** in transcriptomics analysis
- **ProtAgents**: Reinforcement learning for protein structure optimization

**General Science**:
- **Agent Laboratory**: End-to-end research workflow automation
- **Virtual Lab**: Interdisciplinary team meetings for challenge-solving

**Critical Challenges Beyond Literature Review**:
- **Trustworthiness**: Ensuring reliable benchmarking, avoiding overfitting
- **Ethical Concerns**: Bias amplification from training data, hallucinations in critical domains
- **Safety Risks**: Data reliability issues, multi-agent coordination failures, protocol deviation

---

## Connections to Knowledge Base

- **[[Agents lose big picture in long sessions]]** - Literature review requires maintaining coherent understanding across hundreds of papers
- **[[Context engineering replaces prompt engineering]]** - Literature review demands rich context about field evolution, not just paper access
- **[[AI adoption bottleneck is psychological not technical]]** - Scientists may resist AI literature review due to professional identity attachment
- **[[LLMs exhibit significantly lower decision noise than humans]]** - But consistency ≠ contextual understanding
- **Pattern Recognition**: Literature review = pattern recognition across papers (finding themes, contradictions, gaps)
- **Decision-Making**: Critical evaluation of methodology quality = expert judgment under uncertainty
- **Knowledge Synthesis**: Literature review = ultimate synthesis task (integrating disparate findings into coherent narrative)

**Novel Bridge to Epistemology**: Literature review difficulty reveals that **execution is easier than understanding**. Agents can follow protocols (experimentation, data analysis) better than evaluate knowledge validity (literature review).

**Contrarian Implication**: We overestimate AI's understanding capabilities and underestimate execution capabilities. The bottleneck isn't doing the work - it's knowing what work matters.

---

**Tags**: #document-insight #scientific-discovery #literature-review #automation-limits #synthesis #contextual-understanding #research-finding #epistemology
