# GAMMA - Agents Learn Human Cooperation from Simulated Populations or Real Data

**Source**: Collective Intelligence and Multi-Agent AI Systems Research Report, GAMMA (NeurIPS 2024)
**Document Type**: Research Paper
**Extracted By**: AI (document-insight-extractor agent)
**Extraction Date**: 2025-11-21
**Session**: 2025-11-21 Collective Intelligence and Multi-Agent Systems

---

## Core Insight

Generative Agent Modeling for Multi-agent Adaptation (GAMMA) enables AI agents to learn effective human cooperation patterns by training on either simulated human populations or real human datasets. Consistently improves cooperation performance on Overcooked benchmark. This bridges the gap between AI-AI coordination and human-AI collaboration.

---

## Context & Evidence

**Key innovation**: Rather than training agents to cooperate with other agents, GAMMA trains them to cooperate with diverse human behavior patterns. Agents develop models of human preferences, timing, and communication styles.

**Flexibility**: Works with both simulated human populations (cheaper, scalable) and real human behavioral data (more accurate, generalizable).

**Application**: Critical for domains where AI must cooperate with humans (assistive robotics, collaborative tools, autonomous vehicles with human drivers, medical diagnosis teams).

---

## Connections to Knowledge Base

- [[Theory of Mind Essential for Multi-Agent Strategic Collaboration]] - GAMMA implements ToM specifically for human mental models
- [[AI adoption bottleneck is psychological not technical]] - Better human-AI cooperation reduces psychological resistance
- [[Companies want builders not coders]] - Effective human-AI teams require agents trained on human cooperation patterns
- [[Psychological safety enables velocity not comfort]] - GAMMA-trained agents better understand human preferences for psychological safety

---

**Tags**: #document-insight #multi-agent #human-ai-cooperation #marl #theory-of-mind #collaboration #NeurIPS
