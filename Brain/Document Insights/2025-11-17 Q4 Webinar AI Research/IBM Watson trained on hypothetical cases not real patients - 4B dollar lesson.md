# IBM Watson trained on hypothetical cases not real patients - $4B lesson

**Source**: Case Study - IBM Watson for Oncology (2011-2023) - AI Implementation Failure Rates Research Report
**Document Type**: Case Study
**Extracted By**: AI (document-insight-extractor agent)
**Extraction Date**: 2025-11-17
**Session**: 2025-11-17 Q4 Webinar AI Research

---

## Core Insight

IBM invested ~$4 billion in Watson for Oncology, only to shut it down in 2023 because the AI was trained on hypothetical scenarios rather than real-world patient data. World-class technology, infinite resources, but fundamentally flawed data foundation. The lesson: in high-stakes domains, training data quality matters more than model sophistication.

---

## Context & Evidence

**What went wrong**:

1. **Training data flaw**: Trained on hypothetical scenarios, not real-world patient data
2. **Inconsistent recommendations**: Often inappropriate or potentially unsafe treatment suggestions
3. **Lack of localization**: Failed to adapt to different countries' medical guidelines
4. **Bias issues**: Recommendations heavily biased toward Memorial Sloan Kettering's practices
5. **Marketing vs reality gap**: Claims significantly overstated actual capabilities
6. **Inadequate domain expertise**: Struggled to interpret complex, nuanced medical information

**The capability-hype gap**:
- IBM had: Cutting-edge technology, world-class talent, unlimited budget
- IBM lacked: Diverse real-world training data, clinical validation, continuous physician feedback

**Key lesson from report**:
"Healthcare AI requires extensive, diverse training data and continuous refinement. Rigorous real-world testing is non-negotiable in high-stakes domains."

**The mapping to "Three Gaps" Framework**:
1. **Capability Gap**: Insufficient medical domain expertise in AI development
2. **Data Gap**: Training data based on hypothetical cases rather than diverse real-world patients
3. **Culture Gap**: Marketing-driven promises outpaced actual clinical utility; resistance from physicians who found recommendations impractical

---

## Connections to Knowledge Base

- [[84% of AI failures are leadership-driven not technical]] - IBM had technical excellence but leadership chose wrong data foundation
- [[Less than 20% track GenAI KPIs yet tracking has most impact on results]] - IBM tracked technical metrics (model performance) not clinical metrics (patient outcomes, physician trust)
- [[AI adoption bottleneck is psychological not technical - attachment to mental models]] - IBM attached to mental model "better technology = better outcomes" ignoring data quality imperative

**Contrarian insight**: More sophisticated models don't compensate for flawed training data. In high-stakes domains, data quality is non-negotiable regardless of model capability.

**Novel framing**: "Hypothetical scenarios" vs. "real-world data" distinction is critical - synthetic/simulated data may work for some domains but fails catastrophically in medicine where edge cases are life-or-death.

---

**Tags**: #document-insight #IBM-Watson #case-study #data-quality #healthcare-AI #training-data #high-stakes-domains #4-billion-failure
