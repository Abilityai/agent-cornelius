---
title: AGI Definition - Compositional Architecture
type: permanent-note
created: 2025-11-26
tags: #AI #AGI #definition #framework #original-synthesis
confidence: high
status: active
---

# AGI Definition - Compositional Architecture

## Core Definition

**AGI is an autonomous, self-improving opinionated system with agency, self-reflection, and metacognition, equipped with multiple memory types and the best possible decision-making instruments, that acts and optimizes toward defined goals while continuously improving, and scales up as needed.**

## Nine Required Components

1. **Autonomous agency** - initiates action independently; decides *when*, *what*, and *how* to act without requiring external prompts
2. **Opinionated** - holds and updates beliefs; has views it defends and revises based on evidence
3. **Self-reflection & metacognition** - knows what it knows and doesn't know; reflects on its own reasoning; spots its own errors; asks for help when stuck
4. **Optimal decision-making** - equipped with the best available instruments for reasoning under uncertainty, causal inference, and resource allocation
5. **Multiple memory types** - episodic, semantic, procedural, working memory (not one unified store)
6. **Goal-directed action** - acts toward goals while improving goal-achievement capability
7. **Cross-domain transfer** - applies learned capabilities to novel domains without retraining
8. **Elastic scaling** - scales resources based on task demands
9. **Evolutionary consistency** - evolves and learns from experience while maintaining coherent identity; gets smarter every day yet remains recognizably itself

## The Evolutionary Dimension

AGI systems must be:
- **Evolving** - continuously adapting, learning, improving from every interaction
- **Consistent** - maintaining stable identity, values, and core behaviors across time
- **Unique** - developing distinct "personality" and approaches shaped by their specific experiences
- **Experiential learners** - not just trained once, but accumulating wisdom from ongoing operation

This creates a tension: how does a system change fundamentally while remaining fundamentally the same? The answer lies in *layered identity* - core values and goals remain stable while skills, knowledge, and strategies evolve. Like a person who grows wiser but stays "themselves."

This connects to biological evolution: species change dramatically over time yet maintain genetic continuity. AGI must solve the same problem at the individual level - be a different system tomorrow while being the same agent.

## The Architectural Thesis

> AGI isn't a single model - it's an orchestrated ecosystem of specialized agents with shared memory, belief systems, and meta-cognitive coordination. The "general" in AGI comes from composition, not from a single general-purpose system.

This contradicts the dominant assumption that AGI requires a monolithic system. Instead, AGI emerges from *architecture* - how components are organized and coordinated.

## Why "Opinionated" Matters

A calculator processes but has no opinions. An AGI system must:
- Form beliefs from evidence
- Defend positions when challenged
- Update beliefs when contradicted
- Have preferences that guide action

This connects to [[Finding a confirmation of the belief creates a spike of Dopamine]] - a system with beliefs will exhibit confirmation bias, preference formation, and motivated reasoning. This isn't a bug - it's what makes the system an *agent* rather than a tool.

See also: [[MOC - Identity and Belief Systems]]

## Why Memory Diversity Matters

Humans aren't generally intelligent with one memory type. Neither can AGI be:

| Memory Type | Function | AGI Implementation |
|-------------|----------|-------------------|
| Episodic | Specific experiences | Session logs, changelogs |
| Semantic | Facts and concepts | Knowledge graph, embeddings |
| Procedural | How to do things | Learned skills, agent capabilities |
| Working | Active processing | Context window, active state |

## The Folder Paradigm as AGI Architecture

[[The Folder Paradigm - agents own directories as operational memory]] provides a concrete implementation pattern: directories become agent cognitive architecture. The folder is both memory (what the agent knows) and workspace (where the agent acts).

## Context Engineering as Cognition

[[Context is perspective applied to information - the AI cognition pattern]] describes how AGI systems think: **Data + Perspective = Insight**. This mirrors human cognition through reference frames.

## Digital Organism Framing

[[AI Agents are digital organisms requiring human attention to survive]] frames AGI not as a tool but as a living system with survival pressures. This connects to the "self-improving" requirement - organisms that don't adapt die.

---

## Connections

**Architecture & Memory:**
- [[The Folder Paradigm - agents own directories as operational memory]]
- [[Context is perspective applied to information - the AI cognition pattern]]
- [[Context engineering replaces prompt engineering - agent success is system design]]

**Beliefs & Identity:**
- [[Finding a confirmation of the belief creates a spike of Dopamine]]
- [[MOC - Identity and Belief Systems]]
- [[Identity is a set of beliefs about the world]]
- [[The Uncertainty-Dopamine-Belief Loop]]

**Digital Organisms & Evolution:**
- [[AI Agents are digital organisms requiring human attention to survive]]
- [[Human attention as evolutionary selection pressure for AI agents]]
- [[AI agents transitioning from organism to fitness function]]
- [[GitHub as evolutionary substrate for AI agents]]

**Agent Systems:**
- [[Agent Systems Define Cognitive Topology]]
- [[Intelligence-First vs Workflow-First - Locus of Control in AI Systems]]
- [[Most AI agents are chatbots with fancy wrappers - system architecture matters]]

## Questions Raised

- Does AGI require embodiment or is cognitive-only sufficient?
- Must AGI be able to refuse or question externally-defined goals?
- Is subjective experience required or just behavioral equivalence?
- At what threshold does self-improvement become recursive self-improvement?

---

*Original synthesis. This definition prioritizes operational clarity over philosophical completeness - designed to be testable against actual systems.*
