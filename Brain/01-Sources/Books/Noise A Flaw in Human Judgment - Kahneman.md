by [[Daniel Kahneman]] [[Olivier Sibony]] [[Cass Sunstein]]
### **Structure**

**What is [[Noise]]?**

[[Noise is an undesirable variability of judgements]]

**[[Noise]] in Repeated Decisions**

Insurance Company Noise Audit revealed dramatic effect of noice, which was not expected by the executives. Management and most of the executives across the industry expected the difference in [[Judgment]]s to be around 10%. 

The reality is that for the identical cases, the median difference in underwriting was 55%, more than 5x from the estimate. This means that if one underwriter sets the premium at $9500, the other sets it at $16700. 

The estimated cost for this insurance company was hundreds of millions of dollars. 

“A frequent misconception about unwanted variability in judgments is that it doesn’t matter, because random errors supposedly cancel one another out. Certainly, positive and negative errors in a judgment about the same case will tend to cancel one another out, and we will discuss in detail how this property can be used to reduce noise. But noisy systems do not make multiple judgments of the same case. They make noisy judgments of different cases. If one insurance policy is overpriced and another is underpriced, pricing may on average look right, but the insurance company has made two costly errors. If two felons who both should be sentenced to five years in prison receive sentences of three years and seven years, justice has not, on average, been done. In noisy systems, errors do not cancel out. They add up.”

[[In Noisy systems errors don't cancel out they add up]]
[[Noise is contained when multiple estimates averaged out]]

“We depend on the quality of professional judgments, by underwriters, claims adjusters, and others. We assign each case to one expert, but we operate under the wrong assumption that another expert would produce a similar judgment.”

**[[Noise]] in Singular Decisions**

It is much harder to apply the concept of Noise to singular decisions.

This kind of decisions are usually victims of [[Hindsight bias]] and questionable cause analysis. 

[[Singular decisions are as Noisy as Repeated ones]]

[[Judgment is a measurement using a human mind]]

**How [[Judgment]] Happens?**

Story about Gambardi - CEO and Prediction if he stays for the next 2 years. 

The process happens this way

- Of all the cues provided by the description (which are only a subset of what you might need to know), you attended to some more than others without being fully aware of the choices you made.
- Then, you informally integrated these cues into an overall impression of Gambardi’s prospects. Informally and without realizing it, you created a Model of Michael.
- You converted this impression into the number on a scale from 0 to 100. Why specifically the number you chose? It’s unclear, most likely it just came to your mind and you felt like the model of Michael was coherent with this number (and vice-versa).
- You received an **[[Internal Signal of Judgment Completion]]** - your answer feels right.

Each of the steps entails variability and creates noise, as a result, when done among 115 MBA students the results were anywhere between 10 and 95%.

So what you’ve done is a Predictive Judgement, even though it is a Non-verifiable predictive judgement - because the man is fictitious and the answer is probabilistic. 

Even if you had a chance to know if this event actually happened, this is still Unverifiable judgement, because one answer does not reflect if your probability assessment was right or not. 

[[Any probability estimate is non-verifiable judgment]]

[[The goal of the judgement is to find Internal Signal of Judgment Completion]]

[[Judgment]] can be Verifiable and Non-verifiable. In the first ones the noise can be measured by looking at the result, in the second one only by looking into the process. In general practice, whenever there’s uncertainty in the judgement (which is almost always), and the judgement is singular - you should only look at the process optimisation, not the outcome. 

[[Judging people by Results is only reasonable for verifiable judgments]]
[[Decision-Making process needs to be optimised to improve non-verifiable judgments]]

> what people usually claim to strive for in verifiable judgments is a prediction that matches the outcome. What they are effectively trying to achieve, regardless of verifiability, is the internal signal of completion provided by the coherence between the facts of the case and the judgment. And what they should be trying to achieve, normatively speaking, is the judgment process that would produce the best judgment over an ensemble of similar cases.
> 

Evaluative Judgements - e.g. sentencing a felon, setting a valuation. These judgements are problematic in the systems that have the judges to be interchangeable, and assigned randomly and that are expected to give similar results of evaluation. In this case Noise violates the expectations for fairness and consistency. This is a System [[Noise]] - inconsistency, that threatens the credibility of the system. 

**Measuring Error**

People tend to think that errors in different directions will cancel each out. And this is true, when decision is made based on averaging the responses of multiple agents, but this is not working when individual agents make similar decisions with errors positive and negative errors. Those errors just compound. 

Types of [[Noise]]

System Noise2 = Level Noise2 + Pattern Noise2

Level noise is variability in the average level of judgments by different judges.  

Pattern noise is variability in judges’ responses to particular cases.

Occasion [[Noise]] is part of the Pattern Noise - when judges disagree with themselves on the same cases. This is created by mood, level of energy, fatigue, Bullshit receptivity, order of cases. 

**[[Noise]] in Predictive Judgement**

predict their performance evaluations two years after they were hired, also using a 1-to-10 scale.

Monica: Leadership: 4 Communication: 6 Interpersonal skills: 4 Technical skills: 8 Motivation: 8 Your prediction 

Nathalie Leadership: 8 Communication: 10 Interpersonal skills: 6 Technical skills: 7 Motivation: 6 Your prediction

You just did a Clinical Judgement. 

If we created a model or any other machine-driven way of making this judgement, this would be Mechanical Prediction. 

[[Noise is the reason why ML Model beat humans in judgments and forecasts]]

In fact, many types of mechanical approaches, from almost laughably simple rules to the most sophisticated and impenetrable machine algorithms, can outperform human judgment. And one key reason for this outperformance—albeit not the only one—is that all mechanical approaches are noise-free.

**[[Objective Ignorance]]**
[[Objective Ignorance is the limit to what we can know and predict]]

“Wherever there is prediction, there is ignorance, and probably more of it than we think. Have we checked whether the experts we trust are more accurate than dart-throwing chimpanzees?” 

“When you trust your gut because of an internal signal, not because of anything you really know, you are in denial of your [[objective ignorance]].” 

“Models do better than people, but not by much. Mostly, we find mediocre human judgments and slightly better models. Still, better is good, and models are better.” 

“We may never be comfortable using a model to make these decisions—we just need the internal signal to have enough confidence. So let’s make sure we have the best possible decision process.”

By Objective

Predictive Judgements - predict market share

Evaluative Judgements - e.g. sentencing a felon, setting a valuation. 

By Verifiability

Verifiable

Non-Verifiable

By Repeatability

Single Case

Repeatable Cases

By the Number of Judges

Single Judge

Multiple Judges

Reasons for Noise (by type)

**What is noise?**

[[Noise]] the the variability of the decisions made by the same or different people based on the same data. 

[[Noise]] is happening because of the lack of decision procedures [[DMP]] and guidelines, missing data or personal biases of people making an individual decision. 

[[Noise]] tends to cancel itself out in cases when multiple “noisy” agents are involved in making the same decision, and then the result is averaged out. 

However in cases when only one agent looks at each decision noise-caused could be huge. Examples: insurance underwriters, judges, investors coming up with a fare value of the stock. 

People are as much susceptible to noise in individual, one time decisions, as they are in series of decisions. It’s just impossible to measure the scale of the error in one-time scenarios. 

**When we estimate the probability of something we are picking only some factors of the available ones. And then we are finishing the answer that seems the most coherent to our brain. But really the estimate has nothing to do with reality, because we are just looking for the feeling of coherence.**  

[[Average of several estimates of a person is better than the first estimate]]

[[Wisdom of a crowd]]

Group average decisions tend to arrive at the close to the right estimate in the common sense questions that don’t require special knowledge. But it only happens when this is done without consulting each other. If deliberation or communication is done between members of the group - social influences create a lot of noise in the estimates. 

[[Social Information Exchange makes the decision Noise worse]]
[[Wisdom of a crowd only works without social information exchange]]

Even worse - after people talk to each other they tend to end up in the more extreme, polarised points in line with their original inclination. 

Deliberating groups are much noisier than statistical groups, where the decision is made base in just the average of the opinion. 

Early popularity. Early social signals have disproportionate impact on the success of the idea is a social setting. For example, early 5 star reviews drive the engagement and better reviews later. 

[[Early social signals define the success of an idea spread]]

**[[Noise]] in predictive judgements** 

Basic [[linear regression]] models that are modelling a person making a predictive decision are consistently and always better than this person in predictions. Because of the noise created by a person, stable linear predictions are simply better.

In social studies and social predictions, the decisions made by equally weighted model is better than decisions made by a judge or by a liner weighted model. Suggested reason for it is the overfitting of the models to the small size data provided by in social studies. Although models are better but not too much. 

[[People trust algorithms more than people in the beginning (until first mistake)]]

[[AI can fully replace humans  only if it is near-perfect]]

The reason they will never replace humans in full is called **Objective Ignorance** - all the unknowns and factors of uncertainty that we have no idea about, but that have direct influence on the results of the prediction. 

Models are better but not too much and this is because of the same [[Objective ignorance]] or the dark data - realistically missing or unpredictable information. This is basically because any model is the approximation based on the known variable, and every one of them is incomplete. 

Whenever there’s [[causality]] - there’s [[correlation]]. If follows that where there’s causality - we should be able to predict. And correlation, the accuracy of this prediction, is a measure of how much causality we understand. Hence - the correlation is a realistic measure of understanding the subject. [[Objective Ignorance]] sets the ceiling on our understanding. 

We all seem to underestimate our [[Objective Ignorance]] of the world. 

**Heuristics, Biases and Noise**

Heuristics are produced by fast, intuitive thinking, and they are useful, but sometimes lead to Biases. 

Biases always create [[Judgment]] error. If they are identical for different judges - they create Statistical Bias errors. If they are different - they create Noise. 

[[Judgment]] can be described as measurement in which the instrument is a human mind.


[[Noise]]

[[Judgment ]]

[[Objective Ignorance]]

[[Causal Thinking]]