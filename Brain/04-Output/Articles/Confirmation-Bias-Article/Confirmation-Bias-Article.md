# Confirmation Bias

Our minds are built on [[idea]]s, [[Belief]]s and [[value]]s.üí°¬†They shape what we think, how we decide, who we collaborate with. They do that through the means of [[Confirmation Bias]] - one of the most essential mechanisms of our üß†.

‚úÖ How can your friends believe things that seem absolutely outrageous to you‚ùì ‚úÖ How (and why) other people help us to reinforce our beliefs‚ùì ‚úÖ How do you operate when your values are questioned‚ùì ‚úÖ What could be one of the biggest obstacles to your effective decision-making‚ùì‚ùì‚ùì ‚úÖ How Confirmation Bias impacts your business and personal life‚ùì ‚úÖ How do you deal with it to make better decisions‚ùì

Learn about all of that and more in my Youtube debut here üëáüëáüëá

[](https://www.youtube.com/watch?v=HV6iLAiUeF4)[https://www.youtube.com/watch?v=HV6iLAiUeF4](https://www.youtube.com/watch?v=HV6iLAiUeF4)

**1. An idea is like a virus, resilient, highly contagious. The smallest seed of an idea can grow. It can grow to define or destroy you. (Inception)**

2.  you've no idea how true this statement is and how much your [[belief]]s, values and identity are determined by this one mechanism, an approach that your brain has developed over the course of human evolution.
3.  I'm talking about a [[Confirmation Bias]]. In a nutshell, this is a tendency of your brain to unconsciously [[System 1]] select facts that support your [[Opinion]] and ignore or completely discount contradictory [[evidence]].
4. Imagine that there are different [[belief]]s you might have. This can really be anything, any position you hold, any religious or spiritual belief, any political belief.
5. How those beliefs even come about is a whole other question, not for today. But you already have them. Say you believe that the last iPhone is a better smartphone than Samsung flagship
6. There‚Äôs of course a whole range of various facts and opinions you run into in the real world on a daily basis - from the news, social media, friends, things you see, hear or read.
7.  From this universe of [[opinion]]s and assumptions, we automatically seek out those that confirm our [[belief]]s. We give them move value, more weight.
    
For example, you would in all these news and youtube videos, you would notice that iPhone front camera is better, and it‚Äôs got a stronger battery life. However you will probably fail to notice (or more likely - disregard) the facts that Samsung refresh rate is higher and the back camera is better.

And this really is a simplistic example. It is way more complicated when we talk about complex social issues, like firearms, the right for abortion, globalism, political views etc. But the principle stays exactly the same - you see what you want to see.

8.  Then we pick social groups based on the extent to which they're willing to agree with our beliefs. 
9.  These social groups function like an echo chamber of opinions. They reinforce and confirm your beliefs by only showing you things that play along with your original way of thinking. They give you what you want, tell you what you want to hear.
10. Think about your spouse, your friends, your parents, or any other supportive group - [[Confirmatory Group]]. They probably want you to be happy. And one way to make you happy is for them to basically agree with you and support your - sometimes mistaken - beliefs. It feels good.
12. This is actually a neurobiological mechanism: research shows that our brains release [[dopamine]] - a reward molecule - when we find facts that confirm our beliefs. This strengthens the [[belief]], which increases the likelihood that we'll find confirming facts in the future.
11. when the facts don't agree with our beliefs or there are too many conflicting facts, we change the [[Standard of Proof]] so that the facts we don't like become less important and the ones we do like become more important.

For example, if the New York Times writes that a person supports - all good, that's a reliable source of information. But as soon as you see something that contradicts your beliefs - it becomes tabloid, or you suddenly remember that it may have a particular agenda. When all the major media starts saying the same thing you don't want to hear - it's quite possible that people will prefer to join a fringe group of conspiracy theorists who check your beliefs.

13. And this mechanism alone leads to a whole range of cognitive biases that shape our [[Behavior]] and make it harder for us to make good [[decision]]s. I'm talking about

1.  [[Selective perception]]
2.  [[Motivated reasoning]]
3.  commitment & [[Consistency Bias]]
4.  [[Overconfidence effect]]
5.  [[Dunning-Kruger effect]]
6.  [[Self-service bias]]
7.  [[Willful blindness]]
    
9.  so what, you say? This [[bias]] seems to be very important to our normal cognition - it helps us create an illusion of the world that makes sense, that's manageable, and that allows us to make decisions. But at the same time:
    
10.  it allows us humans to be manipulated in an extremely easy way. All the malicious actors have to do is plant an [[idea]] in your brain - through [[Opinion leader]]s or others. And give you a universe of [[information]] that contains corroborating facts. And they just repeat that, over and over again. You don't even have to worry about whether there's truth in that flow of information - our minds do the work on their own, picking out the things we want to see.
    
11.  In [[business]], we fall into the confirmation trap all the time. One of the best examples is when you hire someone [[Hiring]]. Research shows that we shape our [[opinion]] of a person in as little as 30 milliseconds without even realizing it. We put them in the bucket we think they're. And after that, our minds just look for facts to confirm those beliefs.
    
12.  Another example is when we don't re-evaluate the strategy we've chosen. Once we make something per se "ours" (our president, our country, our wife, our car), we're much more inclined to adjust facts and [[Standard of Proof]] to make them look good in our eyes. Therefore, we tend to hold on to dead projects, initiatives, and people much longer than we should. [[Think Again - Adam Grant]]
    
13.  The next question, of course, is how you solve the problem. You don't necessarily always have to avoid it - after all, this mechanism evolved for a reason: It creates the illusion of a manageable world around us.
    

16. But if you want to make a serious [[decision]], you need to make sure you don't fall victim to [[Confirmation Bias]]. How do you do it?

1.  this is one of those biases that's very drastic, but it can fix itself as soon as you notice it. In many cases, this is as simple as remembering that such a thing exists and catching yourself not using it.    
2.  Try to avoid first impressions. Don't draw conclusions from the first few seconds when you meet someone or get to know something.
3.  Question your values. Ask yourself: Why do you think this technology is the future? Why do you think this particular politician sucks? Is there contradictory evidence?
4.  Be intellectually honest with yourself. This definition to me NOT, means that we change the [[Standard of Proof]] depending on where we want to see the outcome.
5.  work in non-confirmatory groups. [[Productive Group]]
    
6.  rely on the [[Scientific thinking]]. The super basic approach described in the scientific method is - you can be Einstein or Newton, but once your hypothesis finds contradictory evidence - it's dead. Unless it's psychology or dietetics - notoriously flawed and inaccurate types of science.
    
7.  rely on data. If possible, use as much data as possible. It can also be manipulated and used as a tool of confirmation bias, but in a less drastic way - you can't unsee the data that shows you're wrong by a wide margin. I mean, you can, but...
    
8.  apply [[Empathy]]. [[Confirmation Bias]] is supposed to work in groups - many people have different opinions, they discuss, argue, fight, but in the end they come to a conclusion that's somewhere in the middle. Think of it this way: if someone has a certain opinion, they probably have their reasons for that opinion. And we don't know their reasons. We don't know their "confirmations." One way to solve that's empathy and [[Active listening]] - try to really hear and understand what the other person is saying. That's the core of effective group collaboration.
    

Facts that confirm our prior [[belief]]s become the next level of beliefs. And this way they build a [[Pyramid of beliefs]] and values, that then shapes your world view and [[identity]].

The trick is that the further this pyramid goes up, the harder it is to destroy it, and the more impact there‚Äôs going to be if it is destroyed. That‚Äôs why it‚Äôs close to impossible to change the opinion of a person that was brainwashed for years, without ruining their [[identity]].