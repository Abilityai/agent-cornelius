# Script 4: The AI Consistency Trap

**Structure**: Problem-Solution
**Word Count**: 78 words

---

## Script:

AI is way more consistent than humans. [PAUSE]

Three to four times less noisy in decision-making.

Sounds great, right?

Here's the trap: low noise doesn't mean high accuracy.

AI can be consistently wrong just as easily as consistently right.

It's the training data problem. Garbage in, consistency out.

So don't confuse reliability with correctness.

Test for both. Or you're building on quicksand.

---

## Delivery Notes:
- [PAUSE] after opening stat | Question with genuine curiosity on "Sounds great, right?" | Emphasize "consistently wrong" | Warning tone on "quicksand"

---

## Source & Reasoning:

**Source**: Eugene's research with Prof. Virginia Cha [[LLMs exhibit significantly lower decision noise than humans]] + November 2024 discussions about AI benchmark gaming and reliability concerns

**Reasoning**: While news focuses on AI hitting performance plateaus, Eugene's empirical research reveals a subtler danger: AI's low noise (consistency) can mask poor accuracy. His study showed GPT-4 has 4.1% noise vs humans' 16.4%, but cautioned "low noise â‰  high accuracy." This is a non-obvious insight that challenges both AI hype (consistency = better) and AI doom (AI is unreliable). Practical framework: test for BOTH consistency AND accuracy.

---

**Date**: 2025-11-14
